{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 15px; height: 80px\">\n",
    "\n",
    "# Project 3\n",
    "\n",
    "### Regression and Classification with the Ames Housing Data\n",
    "\n",
    "---\n",
    "\n",
    "You have just joined a new \"full stack\" real estate company in Ames, Iowa. The strategy of the firm is two-fold:\n",
    "- Own the entire process from the purchase of the land all the way to sale of the house, and anything in between.\n",
    "- Use statistical analysis to optimize investment and maximize return.\n",
    "\n",
    "The company is still small, and though investment is substantial the short-term goals of the company are more oriented towards purchasing existing houses and flipping them as opposed to constructing entirely new houses. That being said, the company has access to a large construction workforce operating at rock-bottom prices.\n",
    "\n",
    "This project uses the [Ames housing data recently made available on kaggle](https://www.kaggle.com/c/house-prices-advanced-regression-techniques)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 1. Estimating the value of homes from fixed characteristics.\n",
    "\n",
    "---\n",
    "\n",
    "Your superiors have outlined this year's strategy for the company:\n",
    "1. Develop an algorithm to reliably estimate the value of residential houses based on *fixed* characteristics.\n",
    "2. Identify characteristics of houses that the company can cost-effectively change/renovate with their construction team.\n",
    "3. Evaluate the mean dollar value of different renovations.\n",
    "\n",
    "Then we can use that to buy houses that are likely to sell for more than the cost of the purchase plus renovations.\n",
    "\n",
    "Your first job is to tackle #1. You have a dataset of housing sale data with a huge amount of features identifying different aspects of the house. The full description of the data features can be found in a separate file:\n",
    "\n",
    "    housing.csv\n",
    "    data_description.txt\n",
    "    \n",
    "You need to build a reliable estimator for the price of the house given characteristics of the house that cannot be renovated. Some examples include:\n",
    "- The neighborhood\n",
    "- Square feet\n",
    "- Bedrooms, bathrooms\n",
    "- Basement and garage space\n",
    "\n",
    "and many more. \n",
    "\n",
    "Some examples of things that **ARE renovate-able:**\n",
    "- Roof and exterior features\n",
    "- \"Quality\" metrics, such as kitchen quality\n",
    "- \"Condition\" metrics, such as condition of garage\n",
    "- Heating and electrical components\n",
    "\n",
    "and generally anything you deem can be modified without having to undergo major construction on the house.\n",
    "\n",
    "---\n",
    "\n",
    "**Your goals:**\n",
    "1. Perform any cleaning, feature engineering, and EDA you deem necessary.\n",
    "- Be sure to remove any houses that are not residential from the dataset.\n",
    "- Identify **fixed** features that can predict price.\n",
    "- Train a model on pre-2010 data and evaluate its performance on the 2010 houses.\n",
    "- Characterize your model. How well does it perform? What are the best estimates of price?\n",
    "\n",
    "> **Note:** The EDA and feature engineering component to this project is not trivial! Be sure to always think critically and creatively. Justify your actions! Use the data description file!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data modules\n",
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "import pandas as pd\n",
    "\n",
    "# Plotting modules\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "# Stats/regressions packages\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "\n",
    "# Make sure your charts appear in the notebook\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format ='retina'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # sorry for that, really\n",
    "\n",
    "import datetime as d_t\n",
    "\n",
    "def display_df(df):\n",
    "    with pd.option_context('display.max_rows', 1000, 'display.max_columns', 1000):\n",
    "        display(df)\n",
    "\n",
    "def list_df(list1d, maxcols=3):\n",
    "    if type(list1d)=='list':\n",
    "        newlist = list1d\n",
    "    else:\n",
    "        newlist = list(list1d)\n",
    "    n = len(newlist) % maxcols\n",
    "    n = 0 if n==0 else (maxcols -n)\n",
    "    if n > 0:\n",
    "        newlist = newlist + [''] * n \n",
    "    df=pd.DataFrame( {' '+str(n) : [v for x,v in enumerate(newlist) if x % maxcols == n] for n in range(maxcols)} )\n",
    "    return df\n",
    "\n",
    "def overview(df, keycol=''): \n",
    "    obs = df.shape[0]\n",
    "    types = df.dtypes\n",
    "    counts = df.apply(lambda x: x.count())\n",
    "    uniques = df.apply(lambda x: [x.unique()])\n",
    "    nuniq = list(df.nunique())\n",
    "    nulls = df.apply(lambda x: x.isnull().sum())\n",
    "    distincts = df.apply(lambda x: x.unique().shape[0])\n",
    "    skewness = df.skew()\n",
    "    kurtosis = df.kurt() \n",
    "    print('Data shape:', df.shape)\n",
    "\n",
    "    dt = df.dtypes.to_frame()\n",
    "    dtitle = 'Data type'\n",
    "    dt.columns = [dtitle]\n",
    "    print( dt.groupby(dtitle)[dtitle].count() )\n",
    "    \n",
    "    if keycol == '':\n",
    "        cols = ['types', 'counts', 'distincts', 'nulls', 'uniques', 'skewness', 'kurtosis']\n",
    "        df_overview = pd.concat([types, counts, distincts, nulls,  uniques, skewness, kurtosis], axis = 1)\n",
    "    else:\n",
    "        corr = df.corr()\n",
    "        cols = ['types', 'counts', 'distincts', 'nulls', 'uniques', 'skewness', 'kurtosis', 'corr' ]\n",
    "        df_overview = pd.concat([types, counts, distincts, nulls, uniques, skewness, kurtosis, corr[keycol]], axis = 1)\n",
    "        \n",
    "    df_overview.columns = cols\n",
    "    df.columns.name=\"Cols\"\n",
    "    df.index.name=\"\"\n",
    "    print('\\n')\n",
    "    return df_overview\n",
    "\n",
    "def dtype_by(df, datatype):\n",
    "    return df.select_dtypes(include=datatype).T.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "house = pd.read_csv('./housing.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyzing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_df(house.head())"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Leaving out the ID column , as it doesn't add any information for our model.\n",
    "just like name of person if any, for most of the cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house.drop(['Id'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checking the columns\n",
    "list_df(house.columns,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# not so clean data\n",
    "house_info = overview(house)\n",
    "\n",
    "# prepare to fix the null values, lookup for the top counts\n",
    "list_null = house_info[house_info.nulls>0].sort_values('nulls',ascending=False).nulls\n",
    "\n",
    "house_info"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Oberservations\n",
    "\n",
    "Results showing those were mostly categorial columns\n",
    "Some continuous variables found, such as:\n",
    "     LotFrontage, GarageYrBlt, MasVnrArea\n",
    "\n",
    "Electrical only has only one case\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df( dtype_by(house,'object') ,5)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Those could be categorial columns, we can map them to values later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# highest 755,000\n",
    "house['SalePrice'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 140,000 high frequency\n",
    "house['SalePrice'].value_counts().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SalePrice is not uniformly distributed and is skewed towards the left .\n",
    "# Quick glance, take this variable to be our objective\n",
    "house['SalePrice'].hist(bins = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use log1p to remove the skewness \n",
    "house['SalePrice'] = np.log(house['SalePrice'])\n",
    "status = house['SalePrice'].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The distribution of SalesPrice is more balanced \n",
    "# Quick glance, take this variable to be our objective\n",
    "house['SalePrice'].hist(bins = 40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to fix these columns having missing values\n",
    "list_null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#after running thru each columns via .unique and listing, basic fixing in action \n",
    "#LotFrontage\n",
    "house['LotFrontage'] = house['LotFrontage'].fillna(0)\n",
    "#Alley\n",
    "house['Alley'] = house['Alley'].fillna('None')\n",
    "#MasVnrType\n",
    "house['MasVnrType'] = house['MasVnrType'].fillna('None')\n",
    "#MasVnrArea\n",
    "house['MasVnrArea'] = house['MasVnrArea'].fillna(0)\n",
    "#BsmtQual\n",
    "house['BsmtQual'] = house['BsmtQual'].fillna('None')\n",
    "#BsmtCond\n",
    "house['BsmtCond'] = house['BsmtCond'].fillna('None')\n",
    "#BsmtExposure\n",
    "house['BsmtExposure'] = house['BsmtExposure'].fillna('None')\n",
    "#BsmtFinType1\n",
    "house['BsmtFinType1'] = house['BsmtFinType1'].fillna('None')\n",
    "#BsmtFinType2\n",
    "house['BsmtFinType2'] = house['BsmtFinType2'].fillna('None')\n",
    "#Electrical\n",
    "house['Electrical'] = house['Electrical'].fillna('None')\n",
    "#FireplaceQu\n",
    "house['FireplaceQu'] = house['FireplaceQu'].fillna('None')\n",
    "#GarageType\n",
    "house['GarageType'] = house['GarageType'].fillna('None')\n",
    "#GarageYrBlt\n",
    "house['GarageYrBlt'] = house['GarageYrBlt'].fillna(0)\n",
    "#GarageFinish\n",
    "house['GarageFinish'] = house['GarageFinish'].fillna(0)\n",
    "#GarageQual\n",
    "house['GarageQual'] = house['GarageQual'].fillna('None')\n",
    "#GarageCond\n",
    "house['GarageCond'] = house['GarageCond'].fillna('None')\n",
    "#PoolQC\n",
    "house['PoolQC'] = house['PoolQC'].fillna('None')\n",
    "#Fence\n",
    "house['Fence'] = house['Fence'].fillna('None')\n",
    "#MiscFeature\n",
    "house['MiscFeature'] = house['MiscFeature'].fillna('None')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#no more missing values\n",
    "house.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list of variables related to \"square feet\"\n",
    "# run below to take a look\n",
    "! grep -i 'square feet' ./data_description.txt"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Oberservation:\n",
    "Other than MasVnrArea, these were found as interger type\n",
    "\n",
    "Could these be float instead of integer ? Such as 'Area' related ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since those area related columns having definition with square feet , should be float\n",
    "list_col = ! grep -i 'square feet' data_description.txt | awk -F: '{ print $1}' | grep -v MasVnrArea\n",
    "print(\"changing data type from int64 to float for :\")\n",
    "for col in list_col:\n",
    "    print(col)\n",
    "    house[col] = house[col].astype(float)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last look , the rest were correctly integer type\n",
    "for x in house.select_dtypes(include='int64').dtypes.items():\n",
    "    col=x[0]\n",
    "    ! grep -i $col data_description.txt\n",
    "\n",
    "# list out those columns to check again    \n",
    "house[ dtype_by(house,'int64') ].head()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Could these be float instead of integer ? Such as 'Area' related ?\n",
    "list_df( dtype_by(house,'int64') ,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house[ dtype_by(house,'int64') ].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find float64 that can be in the continuous variables \n",
    "list_df( dtype_by(house,'float') ,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one of above should be integer for keeping years value.\n",
    "house.GarageYrBlt = house.GarageYrBlt.apply(lambda x: int(x) )\n",
    "house['GarageYrBlt'] = house['GarageYrBlt'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checked , no need to convert anything to integer type\n",
    "house[ dtype_by(house,'float') ].head()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Observations:\n",
    "\n",
    "Found the variables using the calendar year recorded.\n",
    "Those were :\n",
    "\n",
    "              YrSold , YearBuilt  , YearRemodAdd , GarageYrBlt\n",
    "\n",
    "We can convert them to number of years by now.\n",
    "Hence the name of the variables to be respectively as:\n",
    "\n",
    "              Yrs_Sold , Yrs_Built  , Yrs_Remodel , GarageYrsBlt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these will be out of training data\n",
    "list_yrs_col=['YearBuilt', 'YrSold', 'YearRemodAdd', 'GarageYrBlt']\n",
    "house[list_yrs_col][house.YrSold>=2010].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house[list_yrs_col][house.YearBuilt>=2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house[list_yrs_col][house.YearRemodAdd>=2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house[list_yrs_col][house.GarageYrBlt>=2010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(house.YearBuilt.unique())\n",
    "print(house.YrSold.unique())\n",
    "print(house.YearRemodAdd.unique())\n",
    "print(house.GarageYrBlt.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make it number of years by now, later on will rename the columns\n",
    "year_now = d_t.datetime.now().year\n",
    "house['Yrs_Sold'] = house.eval(str(year_now) + ' - YrSold')\n",
    "house['Yrs_Built'] = house.eval(str(year_now) + ' - YearBuilt')\n",
    "house['Yrs_Remodel'] = house.eval(str(year_now) + ' - YearRemodAdd')\n",
    "house['Yrs_GarageBlt'] = house.eval(str(year_now) + ' - GarageYrBlt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_yrs_col=['YearBuilt', 'YrSold', 'YearRemodAdd', 'GarageYrBlt', \\\n",
    "'Yrs_Built', 'Yrs_Remodel' , 'Yrs_GarageBlt' , 'Yrs_Sold']\n",
    "\n",
    "house[list_yrs_col].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rename columns to make it readable if possible\n",
    "\n",
    "house.columns = \\\n",
    "[\"BuildingSalestype\", \"ZoningClassification\", \"StreetDistance\", \"LotSize\", \"Street\", \"Alley\", \\\n",
    "\"GeneralShape\", \"Flatness\", \"Utilities\", \"LotConfig\", \"Slope\", \"Neighborhood\", \"Condition1\", \\\n",
    "\"Condition2\", \"BuildingType\", \"HouseStyle\", \"OverallQuality\", \"RatingCondition\", \"YearBuilt\", \\\n",
    "\"YearRemodAdd\", \"RoofStyle\", \"RoofMaterial\", \"Exterior1st\", \"Exterior2nd\", \"MasonryType\", \"MasonryArea\", \\\n",
    "\"ExteriorQuality\", \"ExterCond\", \"Foundation\", \"BasementHeight\", \"BasementCondition\", \"BasementExposure\",  \\\n",
    "\"RatingBasement1\", \"BasementArea1\", \"RatingBasement2\", \"BasementArea2\", \"BasementUnfinished\", \"TotalBasementArea\",  \\\n",
    "\"Heating\", \"HeatingQC\", \"CentralAir\", \"Electrical\", \"FirstFloor\", \"SecondFloor\", \\\n",
    "\"LowQualFinSF\", \"AreaAboveGround\", \"BsmtFullBath\", \"BsmtHalfBath\", \"FullBath\", \"HalfBath\", \"BedroomAbvGr\", \\\n",
    "\"KitchenAbvGr\", \"KitchenQual\", \"TotRmsAbvGrd\", \"Functional\", \"Fireplaces\", \"FireplaceQu\", \"GarageType\", \\\n",
    "\"GarageYrBlt\", \"GarageFinish\", \"GarageCars\", \"GarageArea\", \"GarageQual\", \"GarageCond\", \"PavedDrive\", \\\n",
    "\"WoodDeckArea\", \"OpenPorchArea\", \"EnclosedPorchArea\", \"SeasonPorchArea\", \"ScreenPorch\", \"PoolArea\", \\\n",
    "\"PoolQC\", \"Fence\", \"MiscFeature\", \"MiscVal\", \"MoSold\", \"YrSold\", \"SaleType\", \"SaleCondition\", \"SalePrice\", \\\n",
    " \"Yrs_Built\", \"Yrs_Sold\", \"Yrs_Remodel\", \"Yrs_GarageBlt\"]\n",
    "\n",
    "house.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove NA for remaining columns if I still missed \n",
    "house.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Comment\n",
    "we can use imputing with KNN approach to fix the missing value instead of force them all to one single value. If time is with me, I prefer to do so."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Quality"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Objective:\n",
    "Be sure to remove any houses that are not residential from the dataset.\n",
    "\n",
    "ZoningClassification\n",
    "       A       Agriculture\n",
    "       C       Commercial\n",
    "       FV       Floating Village Residential\n",
    "       I       Industrial\n",
    "       RH       Residential High Density\n",
    "       RL       Residential Low Density\n",
    "       RP       Residential Low Density Park \n",
    "       RM       Residential Medium Density"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house.drop(house[house.ZoningClassification=='C (all)'].index, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house.groupby('ZoningClassification')['ZoningClassification'].head(1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Objective:\n",
    "Identify fixed features that can predict price."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now clean data, run again\n",
    "house_info = overview(house , \"SalePrice\")\n",
    "house_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Correlation Matrix"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Too many columns , skip the heatmap ! Goes straight to below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_info = overview(house , \"SalePrice\")\n",
    "\n",
    "# looking correlation value to SalesPrice\n",
    "house_info.sort_values(by='corr',ascending=False)['corr'][:25]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "These fixed features is the candidate ?\n",
    "\n",
    "OverallQuality    : Rates the overall material and finish of the house\n",
    "AreaAboveGround   : Above grade (ground) living area square feet\n",
    "GarageCars        : Size of garage in car capacity\n",
    "GarageArea        : Size of garage in square feet\n",
    "1stFlrSF          : First Floor square feet\n",
    "TotalBasementArea : Total square feet of basement area\n",
    "FullBath          : Full bathrooms above grade\n",
    "TotRmsAbvGrd      : Total rooms above grade (does not include bathrooms)\n",
    "\n",
    "Check it out!!       "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "OverallQuality    : Rates the overall material and finish of the house"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 15))\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "fig1 = fig.add_subplot(221); \n",
    "sns.boxplot(x='OverallQuality', y='SalePrice', data=house[['SalePrice', 'OverallQuality']])\n",
    "fig2 = fig.add_subplot(222); \n",
    "sns.scatterplot(x = house.AreaAboveGround, y = house.SalePrice, hue=house.OverallQuality, palette= 'Spectral')\n",
    "fig3 = fig.add_subplot(223); \n",
    "sns.scatterplot(x = house.GarageCars, y = house.SalePrice, hue=house.OverallQuality, palette= 'Spectral')\n",
    "fig4 = fig.add_subplot(224); \n",
    "sns.scatterplot(x = house.GarageArea, y = house.SalePrice, hue=house.OverallQuality, palette= 'Spectral')\n",
    "\n",
    "\n",
    "plt.title(\"Overall Quality\")\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20, 15))\n",
    "sns.set(font_scale=1.5)\n",
    "\n",
    "fig5 = plt.figure(figsize=(16, 8))\n",
    "fig6 = fig5.add_subplot(121); \n",
    "sns.scatterplot(y = house.SalePrice , x = house.TotalBasementArea, hue=house.OverallQuality, palette= 'YlOrRd')\n",
    "fig7 = fig5.add_subplot(122); \n",
    "sns.scatterplot(y = house.SalePrice, x = house['FirstFloor'], hue=house.OverallQuality, palette= 'YlOrRd')\n",
    "fig8 = plt.figure(figsize=(16, 8))\n",
    "fig9 = fig8.add_subplot(121); \n",
    "sns.boxplot(x='FullBath', y='SalePrice', data=house[['SalePrice', 'FullBath']])\n",
    "fig10 = fig8.add_subplot(122); \n",
    "sns.boxplot(x='TotRmsAbvGrd', y='SalePrice', data=house[['SalePrice', 'TotRmsAbvGrd']])\n",
    "\n",
    "plt.title(\"Overall Quality\")\n",
    "plt.tight_layout(); plt.show()\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "From the graph , outliers near the high salesprice exists, explaining high sales price\n",
    "and OverallQuality is the best feature seen graphically that can predice price well.\n",
    "\n",
    "For TotalBasementArea, there 2 outliers on the right side of chart, not indicating high price\n",
    "We can plot it out. Showing before and after outlier removed."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "## \n",
    "AreaAboveGround   : Above grade (ground) living area square feet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(20,5))\n",
    "ax = fig.add_subplot(121)\n",
    "sns.set()\n",
    "sns.scatterplot(x = house.AreaAboveGround, y = house.SalePrice, ax = ax)\n",
    "plt.annotate('Outlier', xy=(4000, 10), xytext=(5642, 11.9), arrowprops=dict(facecolor='g', shrink=0.05)    )\n",
    "plt.annotate('Outlier', xy=(4000, 10), xytext=(4676, 12.1), arrowprops=dict(facecolor='g', shrink=0.05)    )\n",
    "\n",
    "\n",
    "# calculate outliers\n",
    "outlier_high_x = np.mean(house.AreaAboveGround) + np.std(house.AreaAboveGround) * 1.5\n",
    "outlier_low_y = np.mean(house.SalePrice) - np.std(house.SalePrice) * 1.5\n",
    "\n",
    "print(outlier_high_x,outlier_low_y)\n",
    "mask = (house.AreaAboveGround >= outlier_high_x) & (house.SalePrice <= outlier_low_y )\n",
    "#Deleting outliers\n",
    "idx=house.loc[mask].index[0]\n",
    "house.drop( house.index[idx] )\n",
    "mask = (house.AreaAboveGround >= outlier_high_x) & (house.SalePrice <= outlier_low_y )\n",
    "idx=house.loc[mask].index[0]\n",
    "house.drop( house.index[idx], inplace=True )\n",
    "house.drop( house[(house.AreaAboveGround >=4000) & (house.SalePrice <=300000)].index, inplace=True)\n",
    "\n",
    "#Check the graphic again\n",
    "ax = fig.add_subplot(122)\n",
    "sns.scatterplot(x = house.AreaAboveGround, y = house.SalePrice, ax = ax)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Conclusion:\n",
    "We can narrow to some columns as features via correlation values but still need to run the featurs selection process.\n",
    "\n",
    "Those were:\n",
    "OverallQual     0.790982\n",
    "GrLivArea       0.708624\n",
    "GarageCars      0.640409\n",
    "GarageArea      0.623431\n",
    "TotalBsmtSF     0.613581\n",
    "FirstFloor      0.605852\n",
    "FullBath        0.560664\n",
    "TotRmsAbvGrd    0.533723\n",
    "YearBuilt       0.522897\n",
    "YearRemodAdd    0.507101\n",
    "GarageYrBlt     0.486362\n",
    "MasVnrArea      0.477493\n",
    "Fireplaces      0.466929\n",
    "BsmtFinSF1      0.386420\n",
    "LotFrontage     0.351799\n",
    "WoodDeckSF      0.324413\n",
    "SecondFloor     0.319334\n",
    "OpenPorchSF     0.315856\n",
    "HalfBath        0.284108\n",
    "LotArea         0.263843\n",
    "BsmtFullBath    0.227122\n",
    "BsmtUnfSF       0.214479\n",
    "BedroomAbvGr    0.168213\n",
    "ScreenPorch     0.111447"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# more to add as features\n",
    "features = [ \\\n",
    "\"OverallQual\", \"GrLivArea\", \"GarageCars\", \"GarageArea\", \n",
    "\"TotalBsmtSF\", \"FirstFloor\", \"FullBath\", \"TotRmsAbvGrd\", \\\n",
    "\"YearBuilt\", \"YearRemodAdd\", \"GarageYrBlt\", \"MasVnrArea\", \\\n",
    "\"Fireplaces\", \"BsmtFinSF1\", \"LotFrontage\", \"WoodDeckSF\", \\\n",
    "\"SecondFloor\", \"OpenPorchSF\", \"HalfBath\", \"LotArea\", \\\n",
    "\"BsmtFullBath\", \"BsmtUnfSF\", \"BedroomAbvGr\", \"ScreenPorch\" ]"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "More .... come back for more if time spares me\n",
    "such as running knn-impute , combining quality scores, etc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Features Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mapping ordinals features\n",
    "house_info = overview(house , \"SalePrice\")\n",
    "\n",
    "# dictionary of list for columns with unique values <= 10\n",
    "cols_uniq = house_info[house_info.distincts<=10].uniques\n",
    "print(cols_uniq)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('List of columns were categorial can be mapped to digital category')\n",
    "# next, prepare a list of categorial columns \n",
    "categorial_cols = []\n",
    "dict_categories={}\n",
    "for c in cols_uniq.items():\n",
    "    key=c[0]\n",
    "    keylist=c[1][0]\n",
    "    elem=c[1][0][0]   \n",
    "    if len([c for c in str(elem) if c not in '0123456789.'])>0:\n",
    "        dict_categories[key]=keylist\n",
    "        categorial_cols.append(key)\n",
    "\n",
    "print(\"# of columns : \",len(categorial_cols))\n",
    "list_df(categorial_cols, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummydf = pd.get_dummies(house[categorial_cols], columns = categorial_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house = pd.concat([house, dummydf], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in house.columns:\n",
    "    newcol = col.replace('.','').replace('&','')\n",
    "    if col != newcol:\n",
    "        print(col, newcol)\n",
    "        house.rename(columns={col:newcol}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in categorial_cols:\n",
    "    house.drop([col], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 249 columns\n",
    "house.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_df(house.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training Data"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Objective:\n",
    "Train a model on pre-2010 data and evaluate its performance on the 2010 houses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainmask = (house.YearBuilt < 2010) & (house.Yrs_Remodel < 2010) & \\\n",
    "    (house.Yrs_GarageBlt < 2010) & (house.Yrs_Sold < 2010)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_yrs_col=['YearBuilt', 'YrSold', 'YearRemodAdd', 'GarageYrBlt', \\\n",
    "'Yrs_Built', 'Yrs_Remodel' , 'Yrs_GarageBlt' , 'Yrs_Sold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house[list_yrs_col][trainmask].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_train = house[trainmask]\n",
    "house_holdout = house[~trainmask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house.shape, house_train.shape, house_holdout.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_train[list_yrs_col].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# backup all the hardwork to save time\n",
    "house.to_csv('house_clean.csv')\n",
    "house_train.to_csv('house_train.csv')\n",
    "house_holdout.to_csv('house_holdout.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#house = pd.read_csv('house_clean.csv', index_col=[0])\n",
    "#house_train = pd.read_csv('house_train.csv', index_col=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictor and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'SalePrice'\n",
    "house_info = overview(house_train , target)\n",
    "list_cols = [col for col in house_train.columns if col != target]\n",
    "X = house_train[list_cols]\n",
    "y = house_train[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# looking correlation value to SalesPrice\n",
    "house_info.sort_values(by='corr',ascending=False)['corr'][:25]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = [\"OverallQuality\", \"AreaAboveGround\", \"GarageCars\", \"TotalBasementArea\", \\\n",
    "\"GarageArea\", \"FirstFloor\", \"FullBath\", \"YearBuilt\", \"YearRemodAdd\", \\\n",
    "\"GarageYrBlt\", \"TotRmsAbvGrd\", \"Foundation_PConc\", \"ExteriorQuality_Gd\", \\\n",
    "\"BasementHeight_Ex\", \"Fireplaces\", \"HeatingQC_Ex\", \"RatingBasement1_GLQ\", \\\n",
    "\"KitchenQual_Ex\", \"MasonryArea\", \"GarageFinish_Fin\", \"KitchenQual_Gd\", \\\n",
    "\"ExteriorQuality_Ex\", \"OpenPorchArea\", \"BasementArea1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_df(house_train[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_skip = ['SalePrice', 'Neighborhood','Exterior1st','Exterior2nd', 'YearBuilt','YearRemodAdd', 'GarageYrBlt', 'YrSold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_cols = [ x for x in house.columns if x not in cols_to_skip]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "status = house_train.reset_index(drop=True)\n",
    "house_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#status = house_train.reset_index(drop=True)\n",
    "#house_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = house_train[list_cols]\n",
    "y = house_train[target]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# splt training data\n",
    "from sklearn.model_selection import train_test_split\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(X, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X.shape, xTrain.shape, xTest.shape, house_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lasso , Ridge , ElasticNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import Ridge, Lasso, ElasticNet, LinearRegression, RidgeCV, LassoCV, ElasticNetCV\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "linreg = LinearRegression()\n",
    "\n",
    "linreg_scores = cross_val_score(linreg, xTrain, yTrain, cv=10)\n",
    "\n",
    "print(linreg_scores)\n",
    "print(np.mean(linreg_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge_alphas = np.logspace(-2, 7, 50)\n",
    "\n",
    "optimal_ridge = RidgeCV(alphas=ridge_alphas, cv=10)\n",
    "optimal_ridge.fit(xTrain, yTrain)\n",
    "\n",
    "print(optimal_ridge.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ridge = Ridge(alpha=optimal_ridge.alpha_)\n",
    "\n",
    "ridge_scores = cross_val_score(ridge, xTrain, yTrain, cv=10)\n",
    "\n",
    "print(ridge_scores)\n",
    "print(np.mean(ridge_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_lasso = LassoCV(n_alphas=500, cv=10, verbose=1)\n",
    "optimal_lasso.fit(xTrain, yTrain)\n",
    "\n",
    "print(optimal_lasso.alpha_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso = Lasso(alpha=optimal_lasso.alpha_)\n",
    "\n",
    "lasso_scores = cross_val_score(lasso, xTrain, yTrain, cv=10)\n",
    "\n",
    "print(lasso_scores)\n",
    "print(np.mean(lasso_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso.fit(xTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lasso_coefs = pd.DataFrame({'variable':X.columns,\n",
    "                            'coef':lasso.coef_,\n",
    "                            'abs_coef':np.abs(lasso.coef_)})\n",
    "\n",
    "lasso_coefs.sort_values('abs_coef', inplace=True, ascending=False)\n",
    "\n",
    "lasso_coefs.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Percent variables zeroed out:', len(lasso_coefs[lasso_coefs['coef'] == 0])/float(len(lasso_coefs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l1_ratios = np.linspace(0.01, 1.0, 25)\n",
    "\n",
    "optimal_enet = ElasticNetCV(l1_ratio=l1_ratios, \n",
    "                            n_alphas=30, \n",
    "                            cv=10, \n",
    "                            max_iter=10000)\n",
    "optimal_enet.fit(xTrain, yTrain)\n",
    "\n",
    "print(optimal_enet.alpha_)\n",
    "print(optimal_enet.l1_ratio_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "enet = ElasticNet(alpha=optimal_enet.alpha_, \n",
    "                  l1_ratio=optimal_enet.l1_ratio_)\n",
    "\n",
    "enet_scores = cross_val_score(enet, xTrain, yTrain, cv=10)\n",
    "\n",
    "print(enet_scores)\n",
    "print(np.mean(enet_scores))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit the elastic net and ridge outside of cross_val_score\n",
    "ridge.fit(xTrain, xTrain)\n",
    "lasso.fit(xTrain, yTrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## OLS Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.formula.api as sm\n",
    "\n",
    "ln_model = sm.OLS(yTrain,xTrain)\n",
    "result = ln_model.fit()\n",
    "#print(result.summary2())\n",
    "result.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"top 50 best P-Values\")\n",
    "list_p1 = [str(v)+'_'+x for x,v in result.pvalues.items() if v==v]\n",
    "sorted(list_p1,reverse=True)[:10]\n",
    "\n",
    "# exclude 'Utilities_NoSeWa', 'RoofMaterial_Membran'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"# of features = {len(result.pvalues)}\")\n",
    "print(f\"R-Square =  {result.rsquared}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted(list(ln_model.score(result.params)), reverse=True)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_p2 = [str(v)+'_'+x for x,v in result.pvalues.items() if v<0.5]\n",
    "print(f\"P-values below 0.5 , count = {len([str(v)+'_'+x for x,v in result.pvalues.items() if v<0.5])}\")\n",
    "list_p2[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# eliminate some columns, I gpt 93 columns removed\n",
    "def backwardElimination(x, Y, sl, columns):\n",
    "    ini = len(columns)\n",
    "    numVars = x.shape[1]\n",
    "    for i in range(0, numVars):\n",
    "        regressor = sm.OLS(Y, x).fit()\n",
    "        maxVar = max(regressor.pvalues) #.astype(float)\n",
    "        if maxVar > sl:\n",
    "            for j in range(0, numVars - i):\n",
    "                if (regressor.pvalues[j].astype(float) == maxVar):\n",
    "                    columns = np.delete(columns, j)\n",
    "                    x = x.loc[:, columns]\n",
    "                    \n",
    "    print('\\nSelect {:d} features from {:d} by best p-values.'.format(len(columns), ini))\n",
    "    print('The max p-value from the features selecte is {:.3f}.'.format(maxVar))\n",
    "    print(regressor.summary())\n",
    "    \n",
    "    # odds ratios and 95% CI\n",
    "    conf = np.exp(regressor.conf_int())\n",
    "    conf['Odds Ratios'] = np.exp(regressor.params)\n",
    "    conf.columns = ['2.5%', '97.5%', 'Odds Ratios']\n",
    "    display(conf)\n",
    "    \n",
    "    return columns, regressor\n",
    "\n",
    "SL = 0.051\n",
    "pv_cols = list_cols\n",
    "pv_cols, LR = backwardElimination(xTrain, yTrain, SL, pv_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exclude 'Utilities_NoSeWa', 'RoofMaterial_Membran'\n",
    "for col in ['Utilities_NoSeWa', 'RoofMaterial_Membran']:\n",
    "    n=list(pv_cols).index(col)\n",
    "    np.delete(pv_cols,n)\n",
    "\n",
    "smols_columns = pv_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_df( pv_cols ,5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RFECV Recursive Feature Elimination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import RFECV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "\n",
    "ls = Lasso(alpha = 0.0005, max_iter = 161, selection = 'cyclic', tol = 0.002, random_state = 101)\n",
    "rfecv = RFECV(estimator=ls, n_jobs = -1, step=1, scoring = 'neg_mean_squared_error' ,cv=5)\n",
    "selector = rfecv.fit(xTrain, yTrain)\n",
    "\n",
    "#select_features_rfecv = rfecv.get_support()\n",
    "select_features_rfecv=selector.support_\n",
    "#print(selector.support_)\n",
    "print(selector.ranking_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The column names correspond to the ones below. RFECV only excluded a few features.\n",
    "rfecv_columns = np.array(list_cols)[selector.support_]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"eliminated some columns, left with:\",rfecv_columns.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_train[rfecv_columns].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2, f_classif\n",
    "\n",
    "# Build the selector — we'll build one with each score type.\n",
    "skb_f = SelectKBest(f_classif, k=5)\n",
    "skb_chi2 = SelectKBest(chi2, k=5)\n",
    "\n",
    "# Train the selector on the data.\n",
    "skb_f.fit(xTrain, yTrain)\n",
    "\n",
    "try:\n",
    "    skb_chi2.fit(xTrain, yTrain)\n",
    "    # Examine the results.\n",
    "    kbest = pd.DataFrame([list_cols, list(skb_f.scores_), list(skb_chi2.scores_)], \n",
    "                         index=['feature','f_classif','chi2 score']).T.sort_values('f_classif', ascending=False)\n",
    "    \n",
    "except:\n",
    "    # print(\"skip this debugging, no time to troubleshoot\")\n",
    "    kbest = pd.DataFrame([list_cols, list(skb_f.scores_)], \n",
    "                         index=['feature','f_classif']).T.sort_values('f_classif', ascending=False)\n",
    "\n",
    "kbest_columns=kbest.feature.values\n",
    "kbest_scores=kbest[kbest.f_classif <= 50].f_classif\n",
    "kbest[kbest.f_classif <= 50][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbest_columns[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kbest_scores[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selection"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Testing among the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_enet.score(xTest, yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_ridge.score(xTest, yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimal_lasso.score(xTest, yTest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## OLS model prediction not in use"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Selected"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Best score is 0.9165027179895427 from Ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Holdout Test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = 'SalePrice'\n",
    "house_info = overview(house_holdout , target)\n",
    "list_cols = [col for col in house_holdout.columns if col != target]\n",
    "X = house_holdout[xTrain.columns].values\n",
    "y = house_holdout[target].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "house_holdout.shape, house_train.shape, X.shape, xTrain.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    Ypred = optimal_ridge.predict(X)\n",
    "except:\n",
    "    print('unable to work the predictions. failure')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n",
    "score = mean_absolute_error(y_pred=np.expm1(Ypred), y_true=np.expm1(y))\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"the best estimates of price is ${score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypred = optimal_lasso.predict(X)\n",
    "score = mean_absolute_error(y_pred=np.expm1(Ypred), y_true=np.expm1(y))\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypred = optimal_enet.predict(X)\n",
    "score = mean_absolute_error(y_pred=np.expm1(Ypred), y_true=np.expm1(y))\n",
    "score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/l5NasQj.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 2. Determine any value of *changeable* property characteristics unexplained by the *fixed* ones.\n",
    "\n",
    "---\n",
    "\n",
    "Now that you have a model that estimates the price of a house based on its static characteristics, we can move forward with part 2 and 3 of the plan: what are the costs/benefits of quality, condition, and renovations?\n",
    "\n",
    "There are two specific requirements for these estimates:\n",
    "1. The estimates of effects must be in terms of dollars added or subtracted from the house value. \n",
    "2. The effects must be on the variance in price remaining from the first model.\n",
    "\n",
    "The residuals from the first model (training and testing) represent the variance in price unexplained by the fixed characteristics. Of that variance in price remaining, how much of it can be explained by the easy-to-change aspects of the property?\n",
    "\n",
    "---\n",
    "\n",
    "**Your goals:**\n",
    "1. Evaluate the effect in dollars of the renovate-able features. \n",
    "- How would your company use this second model and its coefficients to determine whether they should buy a property or not? Explain how the company can use the two models you have built to determine if they can make money. \n",
    "- Investigate how much of the variance in price remaining is explained by these features.\n",
    "- Do you trust your model? Should it be used to evaluate which properties to buy and fix up?"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# sorry , didn't do in time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/GCAf1UX.png\" style=\"float: left; margin: 25px 15px 0px 0px; height: 25px\">\n",
    "\n",
    "## 3. What property characteristics predict an \"abnormal\" sale?\n",
    "\n",
    "---\n",
    "\n",
    "The `SaleCondition` feature indicates the circumstances of the house sale. From the data file, we can see that the possibilities are:\n",
    "\n",
    "       Normal\tNormal Sale\n",
    "       Abnorml\tAbnormal Sale -  trade, foreclosure, short sale\n",
    "       AdjLand\tAdjoining Land Purchase\n",
    "       Alloca\tAllocation - two linked properties with separate deeds, typically condo with a garage unit\t\n",
    "       Family\tSale between family members\n",
    "       Partial\tHome was not completed when last assessed (associated with New Homes)\n",
    "       \n",
    "One of the executives at your company has an \"in\" with higher-ups at the major regional bank. His friends at the bank have made him a proposal: if he can reliably indicate what features, if any, predict \"abnormal\" sales (foreclosures, short sales, etc.), then in return the bank will give him first dibs on the pre-auction purchase of those properties (at a dirt-cheap price).\n",
    "\n",
    "He has tasked you with determining (and adequately validating) which features of a property predict this type of sale. \n",
    "\n",
    "---\n",
    "\n",
    "**Your task:**\n",
    "1. Determine which features predict the `Abnorml` category in the `SaleCondition` feature.\n",
    "- Justify your results.\n",
    "\n",
    "This is a challenging task that tests your ability to perform classification analysis in the face of severe class imbalance. You may find that simply running a classifier on the full dataset to predict the category ends up useless: when there is bad class imbalance classifiers often tend to simply guess the majority class.\n",
    "\n",
    "It is up to you to determine how you will tackle this problem. I recommend doing some research to find out how others have dealt with the problem in the past. Make sure to justify your solution. Don't worry about it being \"the best\" solution, but be rigorous.\n",
    "\n",
    "Be sure to indicate which features are predictive (if any) and whether they are positive or negative predictors of abnormal sales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorry , didn't do in time"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
